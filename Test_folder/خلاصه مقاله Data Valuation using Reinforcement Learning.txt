این مقاله از کنفرانس PmlR برداشته شده است . (Proceedings of Machine Learning Research)
مقاله مربوط به سال ۲۰۲۰ است .
Data Valuation using Reinforcement Learning
همونطور که می‌دونیم اینکه ما یک سری داده با کیفیت مناسب ( بدون نویز، داده‌های اشتباه) داشته باشیم در نتیجه گیری ما بسیار تاثیرگذار است .
اینجور که داشتن یک دیتاست بزرگ ولی کثیف چه بسا ارزش کمتری از یک دیتاست کوچک ولی با این تفاوت که پراکندگی آن بیان کننده کل ویژگی‌های اصلی دادگان باشد، دارد .
همچنین تشخیص انواع  (Anomalies) در دادگان ما باعث می‌شود که مدل خود را بهتر بشناسیم و دقیق‌تر دسته‌بندی مورد نظر خود را انجام دهیم .
این موضوع یعنی تشخیص بهتر دادگان از موارد مهمی در یادگیری ماشین محسوب می‌شود که به صورت مستقیم بر روی میزان یادگیری و دقت آن تاثیر می‌گذارد .
این جنبه از یادگیری دادگان ما را به سمت کمی کردن ارزش دادگان سوق داده است ، یعنی این که داده‌ای که ما می‌خواهیم آموزش دهیم هر کدام چه میزان اهمیتی در یادگیری داشته باشند و چقدر به فرآیند یادگیری کمک کنند .
کمی کردن ارزش داده ها یک مشکل اساسی در یادگیری ماشین استو دارای چندین مورد استفاده مهم است که عبارتند از :
(1) ایجاد بینش در مورد مجموعه داده و وظیفه، (2) تطبیق دامنه، (3) کشف نمونه خراب، و (4) یادگیری که robust باشد .










همانطور که میدانیم  :
بسیاری از مجموعه‌های داده حاوی نمونه‌های با کیفیت پایین (مثلاً به دلیل سخت‌افزار اندازه‌گیری) یا برچسب‌گذاری نادرست (مثلاً به دلیل خطاهای انسانی) هستند، و در این سناریوها ممکن است با حذف بخش قابل توجهی از نمونه‌های آموزشی، کارایی و دقت مشابه یا حتی بالاتری به دست آید.
علاوه بر این، مجموعه داده‌ها ممکن است شامل عدم تطابق بین داده‌های train و مجموعه‌های test باشد (یعنی مجموعه دادگانی که برای آموزش انتخاب کرده‌ایم بیانگر دقیقی از کل داده‌ها نباشد و شرایطی در تست باشد که برای آموزش در مجموعه دادگان تست موجود نباشد )، و در این موارد می‌توان با انتخاب دقیق نمونه‌های مربوط به سناریوی آزمایشی از مجموعه آموزشی، دقت و کارایی بالاتری را به دست آورد.
برای مقابله با این موضوع، اخیراً کاوش‌های اولیه با روش‌های مبتنی بر جایگشت مانند توابع تاثیر(influence function ) و روش‌های مبتنی بر نظریه بازی مانند Data Shapley انجام شده است.
با این حال، حتی بهترین روش‌های کنونی برای مجموعه داده‌های بزرگ و مدل‌های پیچیده، از نظر محاسباتی امکان‌پذیر نیستند و عملکرد ارزیابی داده‌های آنها محدود است.
برای پرداختن به این چالش‌ها، ما یک رویکرد جدید برای ارزیابی داده‌ها بر اساس meta - learning و بر پایه Rl پیشنهاد می‌کنیم.
ما دراین مقاله کاری که می‌کنیم این هست که : 
یک ماشینی می‌سازیم مبتنی بر Rl که در طول یادگیری یاد می‌گیرد که کدوم داده‌ها برای ما ارزش‌مندتر هستند و به اون داده‌ها وزن بیشتری برای یادگیری  میدهد و داده‌هایی که تاثیر بدی در یادگیری ما 
می‌گذارند رو وزن کمتری براساس تابع پاداش و مجازات می‌دهد.






  

همونطور که در شکل می‌بینیم ما یک سری مجموعه داده‌داریم که وارد یک قسمت به نام
(Data value Estmator (DVE می‌شوند ،‌ سپس به کمک این estimator که یادگیری آن مبتنی بر RL هست داده‌گان وزن می‌گیرند . در مرحله بعد داده‌های به mini batch های مختلف تقسیم می‌شوند و برای یادگیری ماشین اصلی به ماشین اصلی یادگیری داده می‌شوند تا براساس دادگان و وزن جدیدی که دارند مدل را یاد بگیرید ، این مدل بر اساس وزن داده‌ها بهترین مدلی که می‌تواند را یاد میگیرد . در نهایت براساس میزان خطا بهترین مدل بدست آمده مدل Rl خود را که به کمک آن به دیتا وزن می‌دهیم را آپدیت می‌کنیم .
این کار را اینقدر انجام می‌دهیم تا یک مدل داشته باشیم که براساس این نوع دادگان بهترین وزن را به دادگانی بدهد که بیشترین تاثیر را در یادگیری درست دارند و براساس این وزنها، بهترین مدل را می‌سازیم که در نتیجه این مدل بهترین کارکرد را بر روی دادگان دارد با در نظر گرفتن این وزن‌ها، پس علاوه بر یادگیری مدل به یادگیری خود نوع داده و تاثیر آن نیز می‌پردازیم و بهترین مدل را سعی می‌کنیم براساس بهترین مدلی که تابع تاثیر را درست انجام می‌دهد بدست آوردیم .
در این تنظیمات RL، عمل عامل (DVE) انتخاب داده‌های آن است و محیطی که آموزش و ارزیابی مدل پیش‌بینی‌کننده را در بر می‌گیرد، بر اساس وضعیت دسته فعلی داده‌ها، پاداشی را برای هر اقدام می‌دهد. ما الگوریتم REINFORCE (ویلیامز، 1992) را برای بهینه‌سازی با استفاده از گرادیان‌های خط‌مشی تطبیق می‌دهیم و پاداش‌ها را از یک مجموعه اعتبارسنجی کوچک که عملکرد را در کار هدف تقریبی می‌کند، به دست می‌آوریم.






حال یک مدل داریم که وقتی یک سری از دادگان به آن می‌دهیم، می‌توانیم براساس وزنی که دادگان می‌دهد، متوجه شویم که  چه جایگاهی در یادگیری داشته اند هر کدام از این دادگان.
هرچقدر یک داده‌ای کم وزن‌تر،‌  نشان دهنده این است که این داده احتمالا جز دادگان شرایط خاص یا دادگان نویزی هستند که بررسی این موارد می‌تواند به ما بسیار کمک کند .


براساس نتایج بدست آمده از این مقاله ما می‌توانیم چند راه را در نظر بگیریم اینکه دادگانی که خیلی تاثیر بالا در یادگیری را ندارند را حذف کنیم و یا هم دادگانی که تاثیر خیلی خیلی زیادی دارند و هم دادگانی که تاثیر خیلی خیلی کم دارند را حذف کنیم .( حذف دادگان که تاثیر خیلی خیلی زیادی در یادگیری دارند می‌تواند شرایط را برای یادگیری بهتر موارد مرزی فراهم کند )
و خوب نتایجی که گرفته است :