به نام خدا


مهدی فقهی 
۴۰۱۷۲۲۱۳۶
مقاله سوم 
یادگیری ماشین 


ماشین بردار پشتیبان (SVM) به دلیل عملکرد عالی خود به طور گسترده در بسیاری از زمینه ها استفاده شده است.
SVM اصلی فقط می‌تواند داده‌های قابل تفکیک خطی یا تقریباً خطی قابل تفکیک را مدیریت کند، اما به سختی داده‌های غیرخطی را می‌تواند تقسیم بندی کند .
در SVM با مدل هسته نیز مشکلات زیر وجود دارد.        
اول اینکه حجم عظیمی از داده‌ها تولیدی چالش‌هایی را برای طبقه بندی کننده‌های موجود به همراه دارد.
Kernel SVM پیچیدگی محاسباتی بسیار بالایی دارد که باعث می‌شود داده‌های در مقیاس بزرگ واقعاً کند باشند.
دوم اینکه، هسته SVM همواره پارامترهای اضافی را به همراه دارد و ممکن است نیاز به تلاش زیادی برای تنظیم پارامترها برای عملکرد بهتر باشد. تنظیم نادرست هایپر پارامترها اغلب مشکلات بیش از حد برازش یا عدم تناسب را به همراه دارد.
روشی که مقاله ارائه داده است روش DTSVM است .
ماشین بردار پشتیبان درخت تصمیم DTSVM ابتدا SVM خطی را به عنوان طبقه‌بندی‌کننده‌های پایه برای ساخت درخت تصمیم اتخاذ می‌کند و سپس از درخت تصمیم تولید شده برای رمزگذاری داده‌های اصلی در فضای ویژگی جدید استفاده می‌کند.
از آنجایی که ما از SVM خطی به جای SVM هسته در کل روش استفاده می کنیم، DTSVM برای داده های مقیاس بزرگ در مراحل آموزش و آزمایش بسیار کارآمد است.
در سال های اخیر این باور بوجود آمده است که داشتن یک توصیف کننده برای ویژگی‌ها برای کارهای طبقه بندی بسیار مهم است.
یکی از دلایل اصلی موفقیت شبکه عصبی عمیق (DNN) این است که می تواند feature representation را به طور موثر یاد بگیرد. DTSVM در واقع از ایده مشابه پیروی می کند. از درخت برای یادگیری نمایش‌های موثر استفاده می کند و سپس SVM را در فضای ویژگی به دست آمده انجام می دهد که در نهایت منجر به عملکرد برتر می شود.
ما DTSVM را برای مدیریت داده‌های غیرقابل تفکیک خطی در مقیاس بزرگ پیشنهاد می‌کنیم، که ابتدا داده‌ها را در یک فضای ویژگی قابل جداسازی خطی رمزگذاری می‌کند و سپس SVM خطی را روی آن انجام می‌دهد.
در مقاله از نظر تئوری ثابت شده است که اگر درخت تصمیم تولید شده بتواند به دقت 100% دست یابد، داده های کدگذاری شده به صورت خطی قابل تفکیک هستند. علاوه بر این، DTSVM بدون پارامتر است و می‌تواند تأثیر مشکلات overfitting و underfitting را 60 کاهش دهد.


  

در این شکل به خوبی کارکرد این الگوریتم را می‌بینید در اینجا ما برای تابع تصمیم در هر گره از درخت از یک SVM می‌کنیم و به کمک آن دادگان را به دو قسمت تقسیم می‌کنیم هر کدام از این شاخه‌های بدست آمده یک ارائه دهنده برای یکی از درآيه‌های بردار نشان دهنده ویژگی است .
سپس که توانستیم به کمک این درخت یک feature represent خوب بسازیم براساس داده‌های train،‌دادگان را به کمک آن به صورت بردار ویژگی درخواهیم آورد و در انتها بر روی این بردارها یک SVM برای طبقه بندی بکار می‌بریم. 
برای جلوگیری از Overfitting and Underfitting در درخت مورد نظر برای شرط پایان دادن به عمق درخت از شرط‌های زیر استفاده کرده است :
۱. نسبت خطای طبقه بندی روی گره کمتر از آستانه θ است.
۲.تعداد نمونه های روی گره کمتر از آستانه β است.
۳.نسبت label های مثبت به label های منفی کمتر از آستانه γ  شود.